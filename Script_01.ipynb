{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415af151-8a51-489b-9175-2c7c5a80b563",
   "metadata": {},
   "source": [
    "# funcion para obtener informacion sin limite de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36f9f1c8-5dab-430c-8ed1-0e232ed4593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "## Prueba Github\n",
    "\n",
    "# Configuración warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def elasticScroll(elasticParameters, query, pages):\n",
    "    # parametros de salida\n",
    "    # parametros del indice\n",
    "    elasticURL = elasticParameters[\"elasticURL\"]\n",
    "    elasticIndex = elasticParameters[\"elasticIndex\"]\n",
    "    elasticUser = elasticParameters[\"elasticUser\"]\n",
    "    elasticPassword = elasticParameters[\"elasticPassword\"]\n",
    "    \n",
    "    if(len(elasticURL)==0) or (len(elasticIndex)==0) or (len(elasticUser)==0) or (len(elasticPassword)==0):\n",
    "        raise Exception(\"Revisa los parametros\")\n",
    "    # se define la url que apunta al indice de elastic\n",
    "    url_search = f\"{elasticURL}/{elasticIndex}/_search?scroll=1m\"\n",
    "    # se ejecuta la query\n",
    "    response = requests.get(url_search, json=query, auth=HTTPBasicAuth(elasticUser, elasticPassword))\n",
    "    # retorna una lista con el resultado de la query\n",
    "    search = json.loads(response.text)\n",
    "    # guardamos el scroll id correspondiente a la query\n",
    "    scroll_id = search[\"_scroll_id\"]\n",
    "    # url scroll\n",
    "    url_scroll = f\"{elasticURL}/_search/scroll\"\n",
    "    scroll_query = {\n",
    "                \"scroll\": \"1m\",\n",
    "                \"scroll_id\": f\"{scroll_id}\"\n",
    "            }\n",
    "\n",
    "    # condiciones iniciales\n",
    "    scroll_search = {\"hits\":{\"hits\":1}}\n",
    "    if pages:\n",
    "        # hay paginacion\n",
    "        # condiciones iniciales\n",
    "        from_ = pages[\"from\"]\n",
    "        size_ = pages[\"size\"]\n",
    "        count = len(search[\"hits\"][\"hits\"])\n",
    "\n",
    "        while scroll_search[\"hits\"][\"hits\"] and count < from_ + size_:\n",
    "            scroll_response = requests.get(url_scroll, json=scroll_query, auth=HTTPBasicAuth(elasticUser, elasticPassword))\n",
    "            scroll_search = json.loads(scroll_response.text)\n",
    "            if not scroll_search[\"hits\"][\"hits\"]:\n",
    "                continue\n",
    "            else:\n",
    "                search[\"hits\"][\"hits\"].extend(scroll_search[\"hits\"][\"hits\"])\n",
    "            count += len(scroll_search[\"hits\"][\"hits\"])\n",
    "\n",
    "        search[\"hits\"][\"hits\"] = search[\"hits\"][\"hits\"][from_:from_+size_+1]\n",
    "\n",
    "    else:\n",
    "        # Se devuelven todos los resultados\n",
    "        while scroll_search[\"hits\"][\"hits\"]:\n",
    "            scroll_response = requests.get(url_scroll, json=scroll_query,\n",
    "                                           auth=HTTPBasicAuth(elasticUser, elasticPassword))\n",
    "            scroll_search = json.loads(scroll_response.text)\n",
    "            if not scroll_search[\"hits\"][\"hits\"]:\n",
    "                continue\n",
    "            else:\n",
    "                search[\"hits\"][\"hits\"].extend(scroll_search[\"hits\"][\"hits\"])\n",
    "    # Se elina el campo scroll del scroll_body\n",
    "    del scroll_query[\"scroll\"]\n",
    "    # Se elimina el scroll de elasticsearch para liberar memoria\n",
    "    delete = requests.delete(url_scroll, json=scroll_query, auth=HTTPBasicAuth(elasticUser, elasticPassword))\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3328f701-9f28-4152-a314-149c155ba63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiendo parametros de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f5c0705-d3d1-4688-9bee-ddacece2654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos de conexion a elastic\n",
    "elasticParameters = {\"elasticURL\": \"https://es-dev.e-contact.cl\"\n",
    "                    , \"elasticIndex\": \"lea_sequences-events-banco_de_chile\" \n",
    "                    , \"elasticUser\": \"jcalderon\"\n",
    "                    , \"elasticPassword\": \"jcalderon123\"\n",
    "                    }\n",
    "\n",
    "# query custom para obtener fechas\n",
    "query = {\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [],\n",
    "      \"filter\": [\n",
    "        {\n",
    "          \"match_all\": {}\n",
    "        },\n",
    "        { \n",
    "            \n",
    "          \"range\": {\n",
    "            \"interactionData.dateTimeUTC\": {\n",
    "              \"format\": \"strict_date_optional_time\",\n",
    "              \"gte\": \"2022-05-28T00:00:00.000Z\",\n",
    "              \"lte\": \"2022-05-29T00:00:00.000Z\"\n",
    "            }\n",
    "          }\n",
    "         # \"interactionData.interactionId\" :{\"7878d505-9ef5-4e6c-afcd-76b5f2834562\"}  \n",
    "        }\n",
    "      ],\n",
    "      \"should\": [],\n",
    "      \"must_not\": []\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# total de paginas\n",
    "pages =  {\n",
    "    \"from\": 0,\n",
    "    \"size\": 5000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157dc6ea-9045-4d51-a314-d75fd083fbe6",
   "metadata": {},
   "source": [
    "# consulta a indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c685ff-eb24-4093-9a74-35903a2615dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = elasticScroll(elasticParameters, query, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "635f7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto):\n",
    "    \"\"\"\n",
    "    Función para realizar la limpieza de un texto dado.\n",
    "    \"\"\"\n",
    "    # Eliminamos los caracteres especiales\n",
    "   # texto = re.sub(r'\\W', ' ', texto)\n",
    "    # Eliminado las palabras que tengo un solo caracter\n",
    "    texto = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', str(texto))\n",
    "    # Sustituir los espacios en blanco en uno solo\n",
    "    texto = re.sub(r'\\s+', ' ', texto, flags=re.I)\n",
    "    replacements = (\n",
    "        (\"á\", \"a\"),(\"é\", \"e\"),(\"í\", \"i\"),(\"ó\", \"o\"),(\"ú\", \"u\"),\n",
    "        (\"ñ\", \"n\"),(\"?\", \"\"),(\"¿\", \"\"),(\"%\", \"\"),(\"$\", \"\"),\n",
    "        (\"#\", \"\"),(\"&\", \"\"),(\"(\", \"\"),(\")\", \"\"),(\"=\", \"\"),\n",
    "        (\"¡\", \"\"),(\"!\", \"\"),(\"*\", \"\"),(\"+\", \"\"),(\"~\", \"\"),\n",
    "        (\"[\", \"\"),(\"]\", \"\"),(\"}\", \"\"),(\"{\", \"\"),(\"^\", \"\"),\n",
    "        (\"<\", \"\"),(\">\", \"\"),(\"¬\", \"\"),(\"¨\", \"\"),(\"_\", \"\")\n",
    "    )\n",
    "    \n",
    "    for a, b in replacements:\n",
    "        texto = texto.replace(a, b)\n",
    "    # Convertimos textos a minusculas\n",
    "    #texto = texto.lower()\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2a0418-36f5-4a96-bfad-345ae53c8550",
   "metadata": {},
   "source": [
    "# transformar response (dict) a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c4cb52-a5d4-41d3-9f53-2973f8b37f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Activacion de productos': [5.0, 127.0, 0.03937007874015748, 1.0],\n",
       " 'Baja de productos': [1.0, 127.0, 0.007874015748031496, 1.0],\n",
       " 'Clave Digipass': [4.0, 127.0, 0.031496062992125984, 1.0],\n",
       " 'Clave Internet': [2.0, 127.0, 0.015748031496062992, 1.0],\n",
       " 'Consulta compras TD TC': [5.0, 127.0, 0.03937007874015748, 1.0],\n",
       " 'Consulta ejecutivo de cuenta': [1.0, 127.0, 0.007874015748031496, 1.0],\n",
       " 'Consulta estado de cuenta facturacion': [3.0,\n",
       "  127.0,\n",
       "  0.023622047244094488,\n",
       "  1.0],\n",
       " 'Consulta inversiones': [1.0, 127.0, 0.007874015748031496, 1.0],\n",
       " 'Consulta por cheques': [2.0, 127.0, 0.015748031496062992, 1.0],\n",
       " 'Desbloqueo Clave': [4.0, 127.0, 0.031496062992125984, 1.0],\n",
       " 'Emergencias bancarias': [12.0, 127.0, 0.09448818897637795, 1.0],\n",
       " 'NOIDENTIFICADO': [70.0, 127.0, 0.5511811023622047, 1.0],\n",
       " 'Oportunidades de vinculacion': [2.0, 127.0, 0.015748031496062992, 1.0],\n",
       " 'Problemas con plastico': [1.0, 127.0, 0.007874015748031496, 1.0],\n",
       " 'Problemas uso tarjetas': [1.0, 127.0, 0.007874015748031496, 1.0],\n",
       " 'Transferencias': [4.0, 127.0, 0.031496062992125984, 1.0],\n",
       " 'Corte llamado': [2.0, 127.0, 0.015748031496062992, 2.0],\n",
       " 'Red sucursal': [5.0, 127.0, 0.03937007874015748, 2.0],\n",
       " 'Reincidencia': [2.0, 127.0, 0.015748031496062992, 2.0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame, json_normalize\n",
    "import numpy as np\n",
    "\n",
    "df = json_normalize(json.loads(json.dumps(response))[\"hits\"][\"hits\"])\n",
    "df_00 = df [['_source.conversationSequence.topicName','_source.interactionData.interactionId']]\n",
    "\n",
    "# renombra columnas\n",
    "df_00['topicName']= df_00['_source.conversationSequence.topicName']\n",
    "df_00['interactionId']= df_00['_source.interactionData.interactionId']\n",
    "\n",
    "# reemplaza valores vacios por \"NO IDENTIFICADO\"\n",
    "df_00[\"topicName\"] = df_00[\"topicName\"].replace({ \"\": \"NO_IDENTIFICADO\", \" \": \"NO_IDENTIFICADO\" })\n",
    "\n",
    "\n",
    "df_00['topicName'] = df_00.topicName.apply(limpiar_texto)\n",
    "\n",
    "# elimina duplicados\n",
    "df_00 = df_00.drop_duplicates()\n",
    "\n",
    "# crea df 01 agrupando y contando por columna interactionId\n",
    "df_01=df_00.groupby([\"interactionId\"]).size().reset_index(name='cantidad')\n",
    "\n",
    "# concatena ambos df (00 y 01) para crear df 02\n",
    "df_02 = df_00.merge(df_01, how='inner', on='interactionId')\n",
    "#######################################################################\n",
    "\n",
    "# filtro para aplicar en el df 02 cuando el campo cantidad == 1\n",
    "filter01 = df_02[\"cantidad\"]==1\n",
    "df_02.where(filter01, inplace = True)\n",
    "\n",
    "# crea df 03 apartando aquellos registros Nan\n",
    "df_03 = df_02[df_02['cantidad'].notna()]\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "# crea df 04 agrupando y contando por columna interactionId\n",
    "df_04=df_00.groupby([\"interactionId\"]).size().reset_index(name='cantidad')\n",
    "\n",
    "# concatena ambos df (00 y 04) para crear df 05\n",
    "df_05 = df_00.merge(df_04, how='inner', on='interactionId')\n",
    "\n",
    "# filtro para aplicar en el df 05 cuando el campo cantidad != 1\n",
    "filter02 = df_05[\"cantidad\"]!=1\n",
    "df_05.where(filter02, inplace = True)\n",
    "\n",
    "# crea df 06 apartando aquellos registros Nan\n",
    "df_06 = df_05[df_05['cantidad'].notna()]\n",
    "\n",
    "# crea df  apartando aquellos registros cuyo topicName == 'NO_IDENTIFICADO'\n",
    "new_df = df_06[~df_06['topicName'].str.contains(\"NO_IDENTIFICADO\")]\n",
    "\n",
    "# concatena ambos df (03 y new_df) para crear df 01\n",
    "df_01 = pd.concat([df_03, new_df], axis=0)\n",
    "\n",
    "# elimina col cantidad\n",
    "del df_01['cantidad']\n",
    "\n",
    "# crea df \"primario\" con valores que corresponden al grafo 02\n",
    "df_grafo2 = pd.DataFrame({'topicName': ['Corte llamado', 'Red sucursal','Reclamación','Escalamiento de llamada','Reincidencia'], 'matched': True})\n",
    "\n",
    "# agrupa y cuenta los topicos \n",
    "df_02=df_01.groupby([\"topicName\"]).size().reset_index(name='cantidad')\n",
    "\n",
    "# agrega columna total contabilizando el total de interacciones obtenidas en el primer query\n",
    "df_02['Total'] = df_02['cantidad'].sum()\n",
    "\n",
    "# crea df haciendo match entre el total de topicos y aquellos que utiliza el grafo 02\n",
    "df_03 = df_02.merge(df_grafo2, how='left', on='topicName')\n",
    "\n",
    "# selecciona solo aquellos topicos del grafo 01\n",
    "df_03 = df_03[pd.isnull(df_03['matched'])]\n",
    "\n",
    "# crea df haciendo match entre el total de topicos y aquellos que utiliza el grafo 02\n",
    "df_04 = df_02.merge(df_grafo2, how='inner', on='topicName')\n",
    "\n",
    "# reduce cols a utilizar en los df\n",
    "df_grafo01 = df_03[['topicName','cantidad','Total']]\n",
    "df_grafo02 = df_04[['topicName','cantidad','Total']]\n",
    "\n",
    "# calcula el % dividiendo cantidad de apariciones por el total de interacciones\n",
    "df_grafo01['Final'] =((df_grafo01['cantidad']) / df_grafo01['Total'])\n",
    "df_grafo02['Final'] =((df_grafo02['cantidad']) / df_grafo02['Total'])\n",
    "\n",
    "# col grafico determina a cual grafica se deben utilizar los datos\n",
    "df_grafo01['Grafico']=1\n",
    "df_grafo02['Grafico']=2\n",
    "\n",
    "# fusiona y crea solo un df\n",
    "result = pd.concat([df_grafo01, df_grafo02], axis=0)\n",
    "\n",
    "# formatea salidas segun lo solcitado\n",
    "result = result.set_index('topicName').T.to_dict('list')\n",
    "\n",
    "result\n",
    "#df_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24454e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
